{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab_5_Spam_Detection.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vixPqa1zvnxZ"},"source":["Student Name: Marcos David Madrigal Albores\r\n","\r\n","Student Number: 1004731347"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dE0IS4OZvpZJ","executionInfo":{"status":"ok","timestamp":1615742453535,"user_tz":360,"elapsed":1290,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"e675ff2a-10be-4211-da4d-1164a88ad240"},"source":["%%shell\r\n","jupyter nbconvert --to html /content/Lab_5_Spam_Detection_final.ipynb"],"execution_count":45,"outputs":[{"output_type":"stream","text":["[NbConvertApp] Converting notebook /content/Lab_5_Spam_Detection_final.ipynb to html\n","[NbConvertApp] Writing 436638 bytes to /content/Lab_5_Spam_Detection_final.html\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"_bphECiUa9zw"},"source":["# Lab 5: Spam Detection\n","\n","**Deadline**: Monday, March 15, 5:00 PM\n","\n","**Late Penalty**: There is a penalty-free grace period of one hour past the deadline. Any work that is submitted between 1 hour and 24 hours past the deadline will receive a 20% grade deduction. No other late work is accepted. Quercus submission time will be used, not your local computer time. You can submit your labs as many times as you want before the deadline, so please submit often and early.\n","\n","**TA**: Gautam Dawar <gautam.dawar@mail.utoronto.ca>\n","\n","In this assignment, we will build a recurrent neural network to classify a SMS text message\n","as \"spam\" or \"not spam\". In the process, you will\n","    \n","1. Clean and process text data for machine learning.\n","2. Understand and implement a character-level recurrent neural network.\n","3. Use torchtext to build recurrent neural network models.\n","4. Understand batching for a recurrent neural network, and use torchtext to implement RNN batching.\n","\n","### What to submit\n","\n","Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information (.html files are also acceptable).\n","\n","Do not submit any other files produced by your code.\n","\n","Include a link to your colab file in your submission."]},{"cell_type":"markdown","metadata":{"id":"rWiUqJJTa9z6"},"source":["## Colab Link\n","\n","Include a link to your Colab file here. If you would like the TA to look at your\n","Colab file in case your solutions are cut off, **please make sure that your Colab\n","file is publicly accessible at the time of submission**.\n","\n","Colab Link: https://colab.research.google.com/drive/1cVUceT9DHosoeEs9kozg7p80pcTQNndE?usp=sharing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-isbsGP7hNsC","executionInfo":{"status":"ok","timestamp":1615736047088,"user_tz":360,"elapsed":10979,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"7978fc71-a517-4d5d-82a9-445a800ca6d3"},"source":["!git clone https://github.com/Marneus981/Aps360stuff.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'Aps360stuff'...\n","remote: Enumerating objects: 9, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 6227 (delta 1), reused 4 (delta 0), pack-reused 6218\u001b[K\n","Receiving objects: 100% (6227/6227), 305.29 MiB | 38.57 MiB/s, done.\n","Resolving deltas: 100% (342/342), done.\n","Checking out files: 100% (6335/6335), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wZlSGqkzi5JB","executionInfo":{"status":"ok","timestamp":1615736047090,"user_tz":360,"elapsed":10973,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["path_to_folder = \"/content/Aps360stuff/smsspamcollection\"\r\n","path_to_data = \"/content/Aps360stuff/smsspamcollection/SMSSpamCollection\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"HgfNOUaPa9z8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615736049685,"user_tz":360,"elapsed":13557,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"86d468b6-b2a7-406e-a03e-9b4ff2539145"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","torch.manual_seed(981)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f3937dd0b30>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"M0jLI9LBa90C"},"source":["## Part 1. Data Cleaning [15 pt]\n","\n","We will be using the \"SMS Spam Collection Data Set\" available at http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n","\n","There is a link to download the \"Data Folder\" at the very top of the webpage. Download the zip file, unzip it, and upload the file `SMSSpamCollection` to Colab.    "]},{"cell_type":"markdown","metadata":{"id":"sSuF7C_Ga90E"},"source":["### Part (a) [2 pt]\n","\n","Open up the file in Python, and print out one example of a spam SMS, and one example of a non-spam SMS.\n","\n","What is the label value for a spam message, and what is the label value for a non-spam message?"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"I_IfXHeTa90F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615736049686,"user_tz":360,"elapsed":13547,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"5564de01-b268-40a8-baa8-633d0e255dd4"},"source":["counter_h = 0\n","counter_s = 0\n","for line in open(path_to_data):\n","    if ((counter_s == 1)&(counter_h == 1)):\n","      break\n","    if ((line[0] == 'h')&(counter_h == 0)):\n","      counter_h += 1 \n","      print(line)\n","    elif ((line[0] == 's')&(counter_s == 0)):\n","      counter_s += 1 \n","      print(line)\n","\n","#The label for non-spam is ham, the label for spam is spam"],"execution_count":5,"outputs":[{"output_type":"stream","text":["ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n","\n","spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AukA6vMVa90d"},"source":["### Part (b) [1 pt]\n","\n","How many spam messages are there in the data set?\n","How many non-spam messages are there in the data set?\n"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"LgsqyemVa90e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615736049687,"user_tz":360,"elapsed":13538,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"c9e62bd4-ecc5-4525-a2ce-43ba73cc8ae4"},"source":["counter_h = 0\r\n","counter_s = 0\r\n","for line in open(path_to_data):\r\n","  if line[0] == 'h':\r\n","    counter_h += 1\r\n","  elif line[0] == 's':\r\n","    counter_s += 1\r\n","\r\n","print(\"Ham: {0} Spam: {1}\".format(counter_h,counter_s))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Ham: 4827 Spam: 747\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d1WXxVt6a90h"},"source":["### Part (c) [4 pt]\n","\n","We will be using the package `torchtext` to load, process, and batch the data.\n","A tutorial to torchtext is available below. This tutorial uses the same\n","Sentiment140 data set that we explored during lecture.\n","\n","https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8\n","\n","Unlike what we did during lecture, we will be building a **character level RNN**.\n","That is, we will treat each **character** as a token in our sequence,\n","rather than each **word**.\n","\n","Identify two advantage and two disadvantage of modelling SMS text\n","messages as a sequence of characters rather than a sequence of words."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Mhnz8Nk-a90i","executionInfo":{"status":"ok","timestamp":1615736049688,"user_tz":360,"elapsed":13536,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#Advantages\r\n","#1.- Less characters than words, so less storage requirements\r\n","#2.- Expanding on the first point, theres only so many characters, while there might be so pretty\r\n","#obscure or niche words\r\n","#Disadvantages\r\n","#1.- Words convey meaning, characters do not. So while model has to learn th relationship between a couple of words, in \r\n","#this approach it has to learn the realtionships between several characters\r\n","#2.- Per message there are generally more characters than words, so inputs to the model will be much longer (leading to more computation requirements as well)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ie_D0bv9a90k"},"source":["### Part (d) [1 pt]\n","\n","We will be loading our data set using `torchtext.data.TabularDataset`. The\n","constructor will read directly from the `SMSSpamCollection` file. \n","\n","For the data file to be read successfuly, we\n","need to specify the **fields** (columns) in the file. \n","In our case, the dataset has two fields: \n","\n","- a text field containing the sms messages,\n","- a label field which will be converted into a binary label.\n","\n","Split the dataset into `train`, `valid`, and `test`. Use a 60-20-20 split.\n","You may find this torchtext API page helpful:\n","https://torchtext.readthedocs.io/en/latest/data.html#dataset\n","\n","Hint: There is a `Dataset` method that can perform the random split for you."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"P_Y6Puz9a90l","executionInfo":{"status":"ok","timestamp":1615736049858,"user_tz":360,"elapsed":13703,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["import torchtext.legacy as torchtext\n","#import torchtext\n","#As os 0.9.0\n","#torchtext.data.Pipeline -> torchtext.legacy.data.Pipeline\n","#torchtext.data.Batch -> torchtext.legacy.data.Batch\n","#torchtext.data.Example -> torchtext.legacy.data.Example\n","#torchtext.data.Field -> torchtext.legacy.data.Field\n","#torchtext.data.Iterator -> torchtext.legacy.data.Iterator\n","#torchtext.data.Dataset -> torchtext.legacy.data.Dataset\n","text_field = torchtext.data.Field(sequential=True,      # text sequence\n","                                  tokenize=lambda x: x, # because are building a character-RNN\n","                                  include_lengths=True, # to track the length of sequences, for batching\n","                                  batch_first=True,\n","                                  use_vocab=True)       # to turn each character into an integer index\n","label_field = torchtext.data.Field(sequential=False,    # not a sequence\n","                                   use_vocab=False,     # don't need to track vocabulary\n","                                   is_target=True,      \n","                                   batch_first=True,\n","                                   preprocessing=lambda x: int(x == 'spam')) # convert text to 0 and 1\n","\n","fields = [('label', label_field), ('sms', text_field)]\n","dataset = torchtext.data.TabularDataset(path_to_data, # name of the file\n","                                        \"tsv\",               # fields are separated by a tab\n","                                        fields)\n","\n","# dataset[0].sms\n","# dataset[0].label\n","train, valid, test = dataset.split(split_ratio=[0.6,0.2,0.2])"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v6nP0Ks_a90o"},"source":["### Part (e) [2 pt]\n","\n","You saw in part (b) that there are many more non-spam messages than spam messages.\n","This **imbalance** in our training data will be problematic for training.\n","We can fix this disparity by duplicating spam messages in the training set,\n","so that the training set is roughly **balanced**.\n","\n","Explain why having a balanced training set is helpful for training our neural network.\n","\n","Note: if you are not sure, try removing the below code and train your mode."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"FWvx9_rka90p","executionInfo":{"status":"ok","timestamp":1615736049859,"user_tz":360,"elapsed":13701,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["# save the original training examples\n","old_train_examples = train.examples\n","# get all the spam messages in `train`\n","train_spam = []\n","for item in train.examples:\n","    if item.label == 1:\n","        train_spam.append(item)\n","# duplicate each spam message 6 more times\n","train.examples = old_train_examples + train_spam * 6\n","\n","#Answer: If the model is inbalanced it can easily bias itself towards certain\n","#labels and charcateristics to achieve high accuracy, in short it gets lazy(\n","#this model is not learning at all)."],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j7eUmBEva90r"},"source":["### Part (f) [1 pt]\n","\n","We need to build the vocabulary on the training data by running the below code.\n","This finds all the possible character tokens in the training set.\n","\n","Explain what the variables `text_field.vocab.stoi` and `text_field.vocab.itos` represent."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"8CQM8flKa90s","executionInfo":{"status":"ok","timestamp":1615736049860,"user_tz":360,"elapsed":13699,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["text_field.build_vocab(train)\n","#text_field.vocab.stoi\n","#Mapping of character in training set -> numerical identifier\n","#text_field.vocab.itos\n","#List of characters indexed by their corresponding numerical identifiers given\n","#by the above mapping"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TC8WVE8Ua90u"},"source":["### Part (g) [2 pt]\n","\n","The tokens `<unk>` and `<pad>` were not in our SMS text messages.\n","What do these two values represent?"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"y_4Er7KUa90v","executionInfo":{"status":"ok","timestamp":1615736049861,"user_tz":360,"elapsed":13697,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#<unk>\r\n","#These are unknown/not frequent enough characters (such that it was removed\r\n","#from the dictionary)\r\n","#<pad>\r\n","#Padding to make sure the lenght of SMSs stays uniform across a batch"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ff5CNk7Qa90y"},"source":["### Part (h) [2 pt]\n","\n","Since text sequences are of variable length, `torchtext` provides a `BucketIterator` data loader,\n","which batches similar length sequences together. The iterator also provides functionalities to\n","pad sequences automatically.\n","\n","Take a look at 10 batches in `train_iter`. What is the maximum length of the\n","input sequence in each batch? How many `<pad>` tokens are used in each of the 10\n","batches?"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"V8N8qLWOa90y","executionInfo":{"status":"ok","timestamp":1615736049862,"user_tz":360,"elapsed":13695,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["train_iter = torchtext.data.BucketIterator(train,\n","                                           batch_size=32,\n","                                           sort_key=lambda x: len(x.sms), # to minimize padding\n","                                           sort_within_batch=True,        # sort within each batch\n","                                           repeat=False)                  # repeat the iterator for many epochs\n","valid_iter = torchtext.data.BucketIterator(valid,\n","                                           batch_size=32,\n","                                           sort_key=lambda x: len(x.sms), # to minimize padding\n","                                           sort_within_batch=True,        # sort within each batch\n","                                           repeat=False)                  # repeat the iterator for many epochs  \n","test_iter = torchtext.data.BucketIterator(test,\n","                                           batch_size=32,\n","                                           sort_key=lambda x: len(x.sms), # to minimize padding\n","                                           sort_within_batch=True,        # sort within each batch\n","                                           repeat=False)                  # repeat the iterator for many epochs                                         \n","\n","#Take a look at 10 batches in train_iter. \n","#What is the maximum length of the input sequence in each batch? \n","#How many <pad> tokens are used in each of the 10 batches?"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Qwz-rOaha902","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615736050292,"user_tz":360,"elapsed":14115,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"4a4c15aa-f5ae-4c7b-d258-e90e2150b3a7"},"source":["padding = [0]*10\n","maxlen = [0]*10\n","i = 0\n","for batch in train_iter:\n","  if i == 10 : #Only first 10 batches\n","    break\n","  for sms in batch.sms[0]:\n","    for token in sms:\n","      if token == text_field.vocab.stoi['<pad>']:\n","        padding[i] = padding[i] + 1  #Increase padding\n","    if len(sms) > maxlen[i]: #Update maxlen per batch\n","      maxlen[i] = len(sms)\n","  i = i + 1\n","    \n","print('Maximum Lenghts per Batch {}'.format(maxlen))\n","print('Padding per Batch {}'.format(padding))\n","#print('Example sms {}'.format(batch.sms))\n","#print('Example label {}'.format(batch.label))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Maximum Lenghts per Batch [73, 36, 158, 75, 61, 159, 175, 34, 155, 135]\n","Padding per Batch [27, 16, 0, 32, 50, 0, 196, 27, 0, 35]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y7HnqP6_a904"},"source":["## Part 2. Model Building [8 pt]\n","\n","Build a recurrent neural network model, using an architecture of your choosing. \n","Use the one-hot embedding of each character as input to your recurrent network.\n","Use one or more fully-connected layers to make the prediction based on your\n","recurrent network output.\n","\n","Instead of using the RNN output value for the final token, another often used\n","strategy is to max-pool over the entire output array. That is, instead of calling\n","something like:\n","\n","```\n","out, _ = self.rnn(x)\n","self.fc(out[:, -1, :])\n","```\n","\n","where `self.rnn` is an `nn.RNN`, `nn.GRU`, or `nn.LSTM` module, and `self.fc` is a \n","fully-connected \n","layer, we use:\n","\n","```\n","out, _ = self.rnn(x)\n","self.fc(torch.max(out, dim=1)[0])\n","```\n","\n","This works reasonably in practice. An even better alternative is to concatenate the\n","max-pooling and average-pooling of the RNN outputs:\n","\n","```\n","out, _ = self.rnn(x)\n","out = torch.cat([torch.max(out, dim=1)[0], \n","                 torch.mean(out, dim=1)], dim=1)\n","self.fc(out)\n","```\n","\n","We encourage you to try out all these options. The way you pool the RNN outputs\n","is one of the \"hyperparameters\" that you can choose to tune later on."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"jHl1p_Wwa905","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615736050293,"user_tz":360,"elapsed":14105,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"972acf23-f4a6-4db3-f34b-badd3708753d"},"source":["# You might find this code helpful for obtaining\n","# PyTorch one-hot vectors.\n","\n","ident = torch.eye(10)\n","print(ident[0]) # one-hot vector\n","print(ident[1]) # one-hot vector\n","x = torch.tensor([[1, 2], [3, 4]])\n","print(ident[x]) # one-hot vectors"],"execution_count":14,"outputs":[{"output_type":"stream","text":["tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n","\n","        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"4LTQ7zFka909","executionInfo":{"status":"ok","timestamp":1615737495889,"user_tz":360,"elapsed":303,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#Code modified form tutorials 5 and 6\r\n","class CatRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size, pooling = 0):\r\n","        self.name = \"CatRNN\"\r\n","        super(CatRNN, self).__init__()\r\n","        self.pooling = pooling\r\n","        self.input_size = input_size\r\n","        self.hidden_size = hidden_size\r\n","        self.ident = torch.eye(input_size)\r\n","        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\r\n","\r\n","        if pooling == 2: #Change output pooling in response to pooling hyperparameter\r\n","          self.fc = nn.Linear(hidden_size*2, 2) #In case we have to concat\r\n","        else:\r\n","          self.fc = nn.Linear(hidden_size, 2)\r\n","\r\n","    def forward(self, x):\r\n","\r\n","        x_size = x.size(0) #Get size of x for h0\r\n","        h0 = torch.zeros(1, x_size, self.hidden_size) #Hidden 0\r\n","        x, _ = self.rnn(self.ident[x], h0)\r\n","        if self.pooling == 1: #Change pooling\r\n","          x = torch.max(x, dim=1)[0] #Max\r\n","          x = self.fc(x)\r\n","        elif self.pooling == 2:\r\n","          x = torch.cat([torch.max(x, dim=1)[0], torch.mean(x, dim=1)], dim=1)#Concat max and avg\r\n","          x = self.fc(x)\r\n","        else:\r\n","          x = self.fc(x[:,-1,:]) #Normal\r\n","        return x"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKIYPl_Ba90_"},"source":["## Part 3. Training [16 pt]\n","\n","### Part (a) [4 pt]\n","\n","Complete the `get_accuracy` function, which will compute the\n","accuracy (rate) of your model across a dataset (e.g. validation set).\n","You may modify `torchtext.data.BucketIterator` to make your computation\n","faster."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"pvNfhGD6a91A","executionInfo":{"status":"ok","timestamp":1615737497835,"user_tz":360,"elapsed":286,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#Code modified from tutorial 5\n","def get_accuracy(model, data):\n","    \"\"\" Compute the accuracy of the `model` across a dataset `data`\n","    \n","    Example usage:\n","    \n","    >>> model = MyRNN() # to be defined\n","    >>> get_accuracy(model, valid) # the variable `valid` is from above\n","    \"\"\"\n","    data_loader = data #Modified\n","    correct, total = 0, 0\n","    for sms, labels in data_loader:\n","        output = model(sms[0])\n","        pred = output.max(1, keepdim=True)[1]\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        total += labels.shape[0]\n","    return correct / total"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlxlcAC1a91C"},"source":["### Part (b) [4 pt]\n","\n","Train your model. Plot the training curve of your final model. \n","Your training curve should have the training/validation loss and\n","accuracy plotted periodically.\n","\n","Note: Not all of your batches will have the same batch size.\n","In particular, if your training set does not divide evenly by\n","your batch size, there will be a batch that is smaller than\n","the rest. "]},{"cell_type":"code","metadata":{"id":"WBPZlNtLwfu5","executionInfo":{"status":"ok","timestamp":1615737500239,"user_tz":360,"elapsed":290,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["import matplotlib.pyplot as plt # plotting"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nibCE1PS1GT6","executionInfo":{"status":"ok","timestamp":1615737501252,"user_tz":360,"elapsed":449,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"a573378e-fa2d-4f4e-c0a7-efb0fb97a6d5"},"source":["for sms,labels in train_iter:\r\n","  print(sms[0].shape)\r\n","  #print(labels[0].shape)\r\n","  #print(labels[0])"],"execution_count":27,"outputs":[{"output_type":"stream","text":["torch.Size([32, 52])\n","torch.Size([32, 156])\n","torch.Size([32, 142])\n","torch.Size([32, 160])\n","torch.Size([32, 126])\n","torch.Size([32, 63])\n","torch.Size([32, 91])\n","torch.Size([32, 146])\n","torch.Size([32, 152])\n","torch.Size([32, 139])\n","torch.Size([32, 47])\n","torch.Size([32, 204])\n","torch.Size([32, 78])\n","torch.Size([32, 133])\n","torch.Size([32, 114])\n","torch.Size([32, 95])\n","torch.Size([32, 145])\n","torch.Size([32, 33])\n","torch.Size([32, 151])\n","torch.Size([32, 37])\n","torch.Size([32, 25])\n","torch.Size([32, 160])\n","torch.Size([32, 22])\n","torch.Size([32, 158])\n","torch.Size([32, 101])\n","torch.Size([32, 23])\n","torch.Size([32, 154])\n","torch.Size([32, 66])\n","torch.Size([32, 135])\n","torch.Size([32, 116])\n","torch.Size([32, 30])\n","torch.Size([32, 152])\n","torch.Size([32, 156])\n","torch.Size([32, 155])\n","torch.Size([32, 166])\n","torch.Size([32, 54])\n","torch.Size([32, 161])\n","torch.Size([32, 81])\n","torch.Size([32, 48])\n","torch.Size([32, 148])\n","torch.Size([32, 138])\n","torch.Size([32, 41])\n","torch.Size([32, 132])\n","torch.Size([32, 122])\n","torch.Size([32, 141])\n","torch.Size([32, 158])\n","torch.Size([32, 147])\n","torch.Size([32, 135])\n","torch.Size([32, 120])\n","torch.Size([32, 156])\n","torch.Size([32, 160])\n","torch.Size([32, 73])\n","torch.Size([32, 34])\n","torch.Size([32, 45])\n","torch.Size([32, 143])\n","torch.Size([32, 153])\n","torch.Size([32, 149])\n","torch.Size([32, 588])\n","torch.Size([32, 105])\n","torch.Size([32, 163])\n","torch.Size([32, 109])\n","torch.Size([32, 125])\n","torch.Size([32, 111])\n","torch.Size([32, 106])\n","torch.Size([32, 158])\n","torch.Size([32, 74])\n","torch.Size([32, 136])\n","torch.Size([32, 83])\n","torch.Size([32, 159])\n","torch.Size([32, 145])\n","torch.Size([32, 155])\n","torch.Size([32, 26])\n","torch.Size([32, 42])\n","torch.Size([32, 175])\n","torch.Size([32, 159])\n","torch.Size([32, 144])\n","torch.Size([32, 29])\n","torch.Size([32, 71])\n","torch.Size([32, 24])\n","torch.Size([32, 157])\n","torch.Size([32, 27])\n","torch.Size([32, 38])\n","torch.Size([32, 44])\n","torch.Size([32, 16])\n","torch.Size([32, 86])\n","torch.Size([32, 35])\n","torch.Size([32, 39])\n","torch.Size([32, 50])\n","torch.Size([32, 61])\n","torch.Size([32, 130])\n","torch.Size([32, 155])\n","torch.Size([32, 150])\n","torch.Size([32, 57])\n","torch.Size([32, 28])\n","torch.Size([32, 158])\n","torch.Size([32, 154])\n","torch.Size([32, 99])\n","torch.Size([32, 69])\n","torch.Size([32, 32])\n","torch.Size([32, 157])\n","torch.Size([32, 148])\n","torch.Size([32, 126])\n","torch.Size([32, 35])\n","torch.Size([32, 36])\n","torch.Size([32, 109])\n","torch.Size([32, 102])\n","torch.Size([32, 28])\n","torch.Size([32, 52])\n","torch.Size([32, 106])\n","torch.Size([32, 56])\n","torch.Size([32, 144])\n","torch.Size([32, 159])\n","torch.Size([32, 138])\n","torch.Size([32, 145])\n","torch.Size([32, 29])\n","torch.Size([32, 160])\n","torch.Size([32, 134])\n","torch.Size([32, 140])\n","torch.Size([5, 611])\n","torch.Size([32, 120])\n","torch.Size([32, 23])\n","torch.Size([32, 158])\n","torch.Size([32, 142])\n","torch.Size([32, 444])\n","torch.Size([32, 132])\n","torch.Size([32, 71])\n","torch.Size([32, 153])\n","torch.Size([32, 156])\n","torch.Size([32, 155])\n","torch.Size([32, 145])\n","torch.Size([32, 147])\n","torch.Size([32, 155])\n","torch.Size([32, 42])\n","torch.Size([32, 75])\n","torch.Size([32, 32])\n","torch.Size([32, 49])\n","torch.Size([32, 50])\n","torch.Size([32, 152])\n","torch.Size([32, 160])\n","torch.Size([32, 48])\n","torch.Size([32, 112])\n","torch.Size([32, 175])\n","torch.Size([32, 155])\n","torch.Size([32, 24])\n","torch.Size([32, 158])\n","torch.Size([32, 54])\n","torch.Size([32, 31])\n","torch.Size([32, 135])\n","torch.Size([32, 69])\n","torch.Size([32, 27])\n","torch.Size([32, 41])\n","torch.Size([32, 159])\n","torch.Size([32, 154])\n","torch.Size([32, 156])\n","torch.Size([32, 158])\n","torch.Size([32, 81])\n","torch.Size([32, 98])\n","torch.Size([32, 122])\n","torch.Size([32, 73])\n","torch.Size([32, 22])\n","torch.Size([32, 66])\n","torch.Size([32, 137])\n","torch.Size([32, 159])\n","torch.Size([32, 63])\n","torch.Size([32, 161])\n","torch.Size([32, 189])\n","torch.Size([32, 116])\n","torch.Size([32, 78])\n","torch.Size([32, 87])\n","torch.Size([32, 25])\n","torch.Size([32, 164])\n","torch.Size([32, 16])\n","torch.Size([32, 39])\n","torch.Size([32, 92])\n","torch.Size([32, 157])\n","torch.Size([32, 149])\n","torch.Size([32, 150])\n","torch.Size([32, 130])\n","torch.Size([32, 143])\n","torch.Size([32, 156])\n","torch.Size([32, 136])\n","torch.Size([32, 84])\n","torch.Size([32, 46])\n","torch.Size([32, 37])\n","torch.Size([32, 44])\n","torch.Size([32, 162])\n","torch.Size([32, 157])\n","torch.Size([32, 60])\n","torch.Size([32, 151])\n","torch.Size([32, 152])\n","torch.Size([32, 33])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"CVtf7CJCa91D","executionInfo":{"status":"ok","timestamp":1615737504254,"user_tz":360,"elapsed":318,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#Code modified from tutorial 5\r\n","def train_myRNN(model, train_dta, valid_dta, num_epochs=5, learning_rate=1e-5, plot_q=True):\r\n","    #To avoid funky stuff and extra hassle\r\n","    train_loader = train_dta\r\n","    valid_loader = valid_dta\r\n","    ####################\r\n","    criterion = nn.CrossEntropyLoss()\r\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n","    tr_losses, val_losses, train_acc, valid_acc = [], [], [], []\r\n","    epochs_ = 0\r\n","    #Modifications start here\r\n","    for epoch in range(num_epochs):\r\n","        for sms, labels in train_loader: \r\n","          \r\n","          \r\n","          pred = model(sms[0])\r\n","          tr_loss = criterion(pred.float(), labels)\r\n","          tr_loss.backward()\r\n","          optimizer.step()\r\n","          optimizer.zero_grad()\r\n","          #print(\"Its Working! 0\")\r\n","        \r\n","        for sms, labels in valid_loader:\r\n","          pred = model(sms[0])\r\n","          val_loss = criterion(pred.float(), labels)\r\n","          #print(\"Its Working! 1\")\r\n","\r\n","        val_losses.append(float(val_loss))\r\n","        tr_losses.append(float(tr_loss))\r\n","        epochs_ = epochs_ +1\r\n","        train_acc.append(get_accuracy(model, train_loader))\r\n","        valid_acc.append(get_accuracy(model, valid_loader))\r\n","        print(\"Epoch %d; Train Loss %f;Validation Loss %f; Train Acc %f; Val Acc %f\" % (\r\n","                epoch+1, tr_loss,val_loss, train_acc[-1], valid_acc[-1]))\r\n","    \r\n","    epochs = np.arange(1, epochs_ + 1)\r\n","    # plotting\r\n","    if plot_q == True:\r\n","      \r\n","      print(\"Epochs: {0},Learning Rate: {1}\".format(num_epochs, learning_rate))\r\n","      plt.title(\"Training Curve\")\r\n","      plt.plot(epochs,tr_losses, label=\"Train\")\r\n","      plt.plot(epochs,val_losses, label=\"Validation\")\r\n","      plt.xlabel(\"Epoch\")\r\n","      plt.ylabel(\"Loss\")\r\n","      plt.legend(loc='best')\r\n","      plt.show()\r\n","\r\n","      plt.title(\"Training Curve\")\r\n","      plt.plot(epochs, train_acc, label=\"Train\")\r\n","      plt.plot(epochs, valid_acc, label=\"Validation\")\r\n","      plt.xlabel(\"Epoch\")\r\n","      plt.ylabel(\"Accuracy\")\r\n","      plt.legend(loc='best')\r\n","      plt.show()\r\n","\r\n","    print(\"Final Training Loss: {}\".format(tr_losses[-1]))\r\n","    print(\"Final Validation Loss: {}\".format(val_losses[-1]))\r\n","    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\r\n","    print(\"Final Validation Accuracy: {}\".format(valid_acc[-1]))"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":741},"id":"FpZa0Xy-vxUS","executionInfo":{"status":"ok","timestamp":1615736085611,"user_tz":360,"elapsed":49376,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"63f86d99-40f9-45b9-ea29-7d5b6491466d"},"source":["#Default attributes for network\r\n","vocab_len =len(text_field.vocab.itos)\r\n","neuron_number = len(text_field.vocab.itos)\r\n","num_epochs = 5\r\n","pooling = 0\r\n","lr = 1e-4\r\n","#Defaulted training\r\n","\r\n","zerothRNN = CatRNN(input_size = vocab_len, hidden_size = neuron_number, pooling = pooling) \r\n","\r\n","train_myRNN(zerothRNN ,train_iter,valid_iter,num_epochs=num_epochs,learning_rate=lr, plot_q = True)\r\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1; Train Loss 0.711434;Validation Loss 0.693264; Train Acc 0.616105; Val Acc 0.287892\n","Epoch 2; Train Loss 0.441635;Validation Loss 0.311621; Train Acc 0.901233; Val Acc 0.939910\n","Epoch 3; Train Loss 0.286891;Validation Loss 0.184495; Train Acc 0.922104; Val Acc 0.939910\n","Epoch 4; Train Loss 0.680439;Validation Loss 0.206534; Train Acc 0.937223; Val Acc 0.936323\n","Epoch 5; Train Loss 0.229532;Validation Loss 0.080868; Train Acc 0.931800; Val Acc 0.950673\n","Epochs: 5,Learning Rate: 0.0001\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Final Training Loss: 0.22953228652477264\n","Final Validation Loss: 0.08086812496185303\n","Final Training Accuracy: 0.9317995069843878\n","Final Validation Accuracy: 0.9506726457399103\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1w-2zG8VYJ6g","executionInfo":{"status":"ok","timestamp":1615739007035,"user_tz":360,"elapsed":1493104,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"d9f56f37-4242-4494-e213-f79fa9ac1cf8"},"source":["#Potential Hyperparameter Values\r\n","neuron_number_l = [vocab_len,200]\r\n","num_epochs_l = [5,10]\r\n","pooling_l = [0,1,2]\r\n","lr_l = [1e-4,1e-5]\r\n","#Hyperparameter tuning\r\n","i = 0\r\n","for neuron_no in neuron_number_l:\r\n","  for epoch_no in num_epochs_l:\r\n","    for lr_no in lr_l:\r\n","      for pooling_setting in pooling_l:\r\n","        print(\"Model {} Neurons {} Epochs {} Learning Rate {} Pooling Setting {}\".format(i,neuron_no,epoch_no,lr_no,pooling_setting))\r\n","        trialRNN = CatRNN(input_size = vocab_len, hidden_size = neuron_no, pooling = pooling_setting) \r\n","        train_myRNN(trialRNN ,train_iter,valid_iter,num_epochs=epoch_no,learning_rate=lr_no, plot_q = False)\r\n","        i = i+1"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model 0 Neurons 114 Epochs 5 Learning Rate 0.0001 Pooling Setting 0\n","Epoch 1; Train Loss 0.629239;Validation Loss 0.689220; Train Acc 0.713722; Val Acc 0.645740\n","Epoch 2; Train Loss 0.661143;Validation Loss 0.735539; Train Acc 0.738044; Val Acc 0.561435\n","Epoch 3; Train Loss 0.551910;Validation Loss 1.220374; Train Acc 0.553164; Val Acc 0.199103\n","Epoch 4; Train Loss 0.235761;Validation Loss 0.457840; Train Acc 0.857518; Val Acc 0.859193\n","Epoch 5; Train Loss 0.335043;Validation Loss 0.242361; Train Acc 0.901561; Val Acc 0.935426\n","Final Training Loss: 0.335042804479599\n","Final Validation Loss: 0.242361381649971\n","Final Training Accuracy: 0.9015612161051767\n","Final Validation Accuracy: 0.9354260089686098\n","Model 1 Neurons 114 Epochs 5 Learning Rate 0.0001 Pooling Setting 1\n","Epoch 1; Train Loss 0.700103;Validation Loss 0.743611; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 2; Train Loss 0.431368;Validation Loss 0.373568; Train Acc 0.917009; Val Acc 0.947982\n","Epoch 3; Train Loss 0.190263;Validation Loss 0.291026; Train Acc 0.937387; Val Acc 0.949776\n","Epoch 4; Train Loss 0.109342;Validation Loss 0.287527; Train Acc 0.944618; Val Acc 0.952466\n","Epoch 5; Train Loss 0.269732;Validation Loss 0.194275; Train Acc 0.948562; Val Acc 0.965022\n","Final Training Loss: 0.26973187923431396\n","Final Validation Loss: 0.19427533447742462\n","Final Training Accuracy: 0.9485620377978636\n","Final Validation Accuracy: 0.9650224215246637\n","Model 2 Neurons 114 Epochs 5 Learning Rate 0.0001 Pooling Setting 2\n","Epoch 1; Train Loss 0.705292;Validation Loss 0.709724; Train Acc 0.561709; Val Acc 0.221525\n","Epoch 2; Train Loss 0.706114;Validation Loss 0.746426; Train Acc 0.614133; Val Acc 0.313004\n","Epoch 3; Train Loss 0.346873;Validation Loss 0.456054; Train Acc 0.929006; Val Acc 0.958744\n","Epoch 4; Train Loss 0.204200;Validation Loss 0.146294; Train Acc 0.931142; Val Acc 0.959641\n","Epoch 5; Train Loss 0.441100;Validation Loss 0.199950; Train Acc 0.925883; Val Acc 0.963229\n","Final Training Loss: 0.4410998821258545\n","Final Validation Loss: 0.19995014369487762\n","Final Training Accuracy: 0.9258833196384553\n","Final Validation Accuracy: 0.9632286995515695\n","Model 3 Neurons 114 Epochs 5 Learning Rate 1e-05 Pooling Setting 0\n","Epoch 1; Train Loss 0.693257;Validation Loss 0.658073; Train Acc 0.529663; Val Acc 0.843049\n","Epoch 2; Train Loss 0.661589;Validation Loss 0.658854; Train Acc 0.549219; Val Acc 0.817937\n","Epoch 3; Train Loss 0.680179;Validation Loss 0.663344; Train Acc 0.581594; Val Acc 0.800000\n","Epoch 4; Train Loss 0.693873;Validation Loss 0.670944; Train Acc 0.615776; Val Acc 0.785650\n","Epoch 5; Train Loss 0.678588;Validation Loss 0.681113; Train Acc 0.664749; Val Acc 0.617040\n","Final Training Loss: 0.6785882711410522\n","Final Validation Loss: 0.6811125874519348\n","Final Training Accuracy: 0.6647493837304848\n","Final Validation Accuracy: 0.6170403587443947\n","Model 4 Neurons 114 Epochs 5 Learning Rate 1e-05 Pooling Setting 1\n","Epoch 1; Train Loss 0.687723;Validation Loss 0.697208; Train Acc 0.589318; Val Acc 0.269058\n","Epoch 2; Train Loss 0.705420;Validation Loss 0.707404; Train Acc 0.543139; Val Acc 0.173094\n","Epoch 3; Train Loss 0.706357;Validation Loss 0.700804; Train Acc 0.532293; Val Acc 0.155157\n","Epoch 4; Train Loss 0.652799;Validation Loss 0.670161; Train Acc 0.532950; Val Acc 0.155157\n","Epoch 5; Train Loss 0.695845;Validation Loss 0.711283; Train Acc 0.533936; Val Acc 0.156054\n","Final Training Loss: 0.6958447098731995\n","Final Validation Loss: 0.7112833857536316\n","Final Training Accuracy: 0.533935907970419\n","Final Validation Accuracy: 0.15605381165919283\n","Model 5 Neurons 114 Epochs 5 Learning Rate 1e-05 Pooling Setting 2\n","Epoch 1; Train Loss 0.671243;Validation Loss 0.755283; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 2; Train Loss 0.773580;Validation Loss 0.753456; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 3; Train Loss 0.733491;Validation Loss 0.701899; Train Acc 0.526048; Val Acc 0.144395\n","Epoch 4; Train Loss 0.655353;Validation Loss 0.683074; Train Acc 0.527034; Val Acc 0.144395\n","Epoch 5; Train Loss 0.611520;Validation Loss 0.730630; Train Acc 0.527198; Val Acc 0.146188\n","Final Training Loss: 0.6115202903747559\n","Final Validation Loss: 0.7306300401687622\n","Final Training Accuracy: 0.5271980279375513\n","Final Validation Accuracy: 0.14618834080717488\n","Model 6 Neurons 114 Epochs 10 Learning Rate 0.0001 Pooling Setting 0\n","Epoch 1; Train Loss 0.668918;Validation Loss 0.685216; Train Acc 0.639277; Val Acc 0.530045\n","Epoch 2; Train Loss 0.935720;Validation Loss 0.308505; Train Acc 0.778800; Val Acc 0.921076\n","Epoch 3; Train Loss 0.434282;Validation Loss 0.435322; Train Acc 0.899589; Val Acc 0.921076\n","Epoch 4; Train Loss 0.622134;Validation Loss 0.228149; Train Acc 0.781265; Val Acc 0.905830\n","Epoch 5; Train Loss 0.249244;Validation Loss 0.056823; Train Acc 0.906656; Val Acc 0.944395\n","Epoch 6; Train Loss 0.271844;Validation Loss 0.226504; Train Acc 0.915037; Val Acc 0.919283\n","Epoch 7; Train Loss 0.358428;Validation Loss 0.165092; Train Acc 0.911257; Val Acc 0.951570\n","Epoch 8; Train Loss 0.300065;Validation Loss 0.360157; Train Acc 0.927691; Val Acc 0.916592\n","Epoch 9; Train Loss 0.128578;Validation Loss 0.306769; Train Acc 0.937716; Val Acc 0.930942\n","Epoch 10; Train Loss 0.400571;Validation Loss 0.630067; Train Acc 0.942810; Val Acc 0.942601\n","Final Training Loss: 0.4005711078643799\n","Final Validation Loss: 0.6300672292709351\n","Final Training Accuracy: 0.942810188989318\n","Final Validation Accuracy: 0.9426008968609866\n","Model 7 Neurons 114 Epochs 10 Learning Rate 0.0001 Pooling Setting 1\n","Epoch 1; Train Loss 0.628706;Validation Loss 0.695931; Train Acc 0.646343; Val Acc 0.382960\n","Epoch 2; Train Loss 0.545374;Validation Loss 0.549538; Train Acc 0.936401; Val Acc 0.947982\n","Epoch 3; Train Loss 0.323913;Validation Loss 0.480504; Train Acc 0.929334; Val Acc 0.962332\n","Epoch 4; Train Loss 0.285466;Validation Loss 0.223092; Train Acc 0.933279; Val Acc 0.967713\n","Epoch 5; Train Loss 0.083373;Validation Loss 0.152340; Train Acc 0.932621; Val Acc 0.971300\n","Epoch 6; Train Loss 0.114344;Validation Loss 0.332349; Train Acc 0.956615; Val Acc 0.959641\n","Epoch 7; Train Loss 0.596481;Validation Loss 0.124910; Train Acc 0.958094; Val Acc 0.966816\n","Epoch 8; Train Loss 0.126162;Validation Loss 0.146367; Train Acc 0.953328; Val Acc 0.970404\n","Epoch 9; Train Loss 0.160869;Validation Loss 0.122251; Train Acc 0.962366; Val Acc 0.961435\n","Epoch 10; Train Loss 0.022861;Validation Loss 0.120033; Train Acc 0.963681; Val Acc 0.962332\n","Final Training Loss: 0.02286135032773018\n","Final Validation Loss: 0.12003308534622192\n","Final Training Accuracy: 0.9636811832374692\n","Final Validation Accuracy: 0.9623318385650225\n","Model 8 Neurons 114 Epochs 10 Learning Rate 0.0001 Pooling Setting 2\n","Epoch 1; Train Loss 0.603547;Validation Loss 0.655751; Train Acc 0.548562; Val Acc 0.200000\n","Epoch 2; Train Loss 0.742848;Validation Loss 0.798509; Train Acc 0.540181; Val Acc 0.175785\n","Epoch 3; Train Loss 0.409491;Validation Loss 0.384635; Train Acc 0.941495; Val Acc 0.951570\n","Epoch 4; Train Loss 0.145707;Validation Loss 0.333181; Train Acc 0.950370; Val Acc 0.949776\n","Epoch 5; Train Loss 0.565632;Validation Loss 0.668613; Train Acc 0.533279; Val Acc 0.162332\n","Epoch 6; Train Loss 0.381133;Validation Loss 0.526404; Train Acc 0.950534; Val Acc 0.955157\n","Epoch 7; Train Loss 0.393360;Validation Loss 0.286445; Train Acc 0.950863; Val Acc 0.965919\n","Epoch 8; Train Loss 0.135577;Validation Loss 0.227170; Train Acc 0.950370; Val Acc 0.969507\n","Epoch 9; Train Loss 0.078571;Validation Loss 0.234148; Train Acc 0.947576; Val Acc 0.969507\n","Epoch 10; Train Loss 0.077855;Validation Loss 0.237409; Train Acc 0.950370; Val Acc 0.968610\n","Final Training Loss: 0.07785544544458389\n","Final Validation Loss: 0.23740914463996887\n","Final Training Accuracy: 0.9503697617091208\n","Final Validation Accuracy: 0.968609865470852\n","Model 9 Neurons 114 Epochs 10 Learning Rate 1e-05 Pooling Setting 0\n","Epoch 1; Train Loss 0.768855;Validation Loss 0.767195; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 2; Train Loss 0.628726;Validation Loss 0.707572; Train Acc 0.525883; Val Acc 0.143498\n","Epoch 3; Train Loss 0.644832;Validation Loss 0.744529; Train Acc 0.525883; Val Acc 0.142601\n","Epoch 4; Train Loss 0.753587;Validation Loss 0.750847; Train Acc 0.526541; Val Acc 0.143498\n","Epoch 5; Train Loss 0.632208;Validation Loss 0.754040; Train Acc 0.537223; Val Acc 0.155157\n","Epoch 6; Train Loss 0.644283;Validation Loss 0.732337; Train Acc 0.551191; Val Acc 0.181166\n","Epoch 7; Train Loss 0.618912;Validation Loss 0.691598; Train Acc 0.624158; Val Acc 0.408072\n","Epoch 8; Train Loss 0.652049;Validation Loss 0.677389; Train Acc 0.716023; Val Acc 0.647534\n","Epoch 9; Train Loss 0.566812;Validation Loss 0.608419; Train Acc 0.853903; Val Acc 0.889686\n","Epoch 10; Train Loss 0.564185;Validation Loss 0.527032; Train Acc 0.819556; Val Acc 0.756054\n","Final Training Loss: 0.5641853213310242\n","Final Validation Loss: 0.5270319581031799\n","Final Training Accuracy: 0.819556285949055\n","Final Validation Accuracy: 0.7560538116591928\n","Model 10 Neurons 114 Epochs 10 Learning Rate 1e-05 Pooling Setting 1\n","Epoch 1; Train Loss 0.689435;Validation Loss 0.694271; Train Acc 0.477896; Val Acc 0.206278\n","Epoch 2; Train Loss 0.701785;Validation Loss 0.712474; Train Acc 0.533114; Val Acc 0.157848\n","Epoch 3; Train Loss 0.672756;Validation Loss 0.719276; Train Acc 0.527691; Val Acc 0.146188\n","Epoch 4; Train Loss 0.672873;Validation Loss 0.715895; Train Acc 0.525883; Val Acc 0.143498\n","Epoch 5; Train Loss 0.724174;Validation Loss 0.724466; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 6; Train Loss 0.692532;Validation Loss 0.728922; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 7; Train Loss 0.715267;Validation Loss 0.729234; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 8; Train Loss 0.640180;Validation Loss 0.730158; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 9; Train Loss 0.729163;Validation Loss 0.727484; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 10; Train Loss 0.647049;Validation Loss 0.734587; Train Acc 0.525883; Val Acc 0.143498\n","Final Training Loss: 0.6470485329627991\n","Final Validation Loss: 0.7345866560935974\n","Final Training Accuracy: 0.5258833196384552\n","Final Validation Accuracy: 0.14349775784753363\n","Model 11 Neurons 114 Epochs 10 Learning Rate 1e-05 Pooling Setting 2\n","Epoch 1; Train Loss 0.639511;Validation Loss 0.786642; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 2; Train Loss 0.699490;Validation Loss 0.663854; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 3; Train Loss 0.659991;Validation Loss 0.769659; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 4; Train Loss 0.610961;Validation Loss 0.761186; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 5; Train Loss 0.755921;Validation Loss 0.788200; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 6; Train Loss 0.615539;Validation Loss 0.646412; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 7; Train Loss 0.752680;Validation Loss 0.637865; Train Acc 0.525883; Val Acc 0.142601\n","Epoch 8; Train Loss 0.648785;Validation Loss 0.766512; Train Acc 0.527691; Val Acc 0.147085\n","Epoch 9; Train Loss 0.567786;Validation Loss 0.704397; Train Acc 0.528841; Val Acc 0.150673\n","Epoch 10; Train Loss 0.707408;Validation Loss 0.720643; Train Acc 0.537058; Val Acc 0.163229\n","Final Training Loss: 0.707407534122467\n","Final Validation Loss: 0.720643162727356\n","Final Training Accuracy: 0.5370583401807724\n","Final Validation Accuracy: 0.16322869955156952\n","Model 12 Neurons 200 Epochs 5 Learning Rate 0.0001 Pooling Setting 0\n","Epoch 1; Train Loss 0.744774;Validation Loss 0.494587; Train Acc 0.798685; Val Acc 0.914798\n","Epoch 2; Train Loss 0.376534;Validation Loss 0.563789; Train Acc 0.718324; Val Acc 0.654709\n","Epoch 3; Train Loss 0.522197;Validation Loss 0.272667; Train Acc 0.911093; Val Acc 0.921973\n","Epoch 4; Train Loss 0.020916;Validation Loss 0.253422; Train Acc 0.923911; Val Acc 0.937220\n","Epoch 5; Train Loss 0.264404;Validation Loss 0.318091; Train Acc 0.922597; Val Acc 0.902242\n","Final Training Loss: 0.2644041180610657\n","Final Validation Loss: 0.3180907964706421\n","Final Training Accuracy: 0.9225965488907149\n","Final Validation Accuracy: 0.9022421524663677\n","Model 13 Neurons 200 Epochs 5 Learning Rate 0.0001 Pooling Setting 1\n","Epoch 1; Train Loss 0.683713;Validation Loss 0.736307; Train Acc 0.569762; Val Acc 0.233184\n","Epoch 2; Train Loss 0.250142;Validation Loss 0.459548; Train Acc 0.944618; Val Acc 0.956951\n","Epoch 3; Train Loss 0.191511;Validation Loss 0.341743; Train Acc 0.954643; Val Acc 0.961435\n","Epoch 4; Train Loss 0.129953;Validation Loss 0.355525; Train Acc 0.954971; Val Acc 0.967713\n","Epoch 5; Train Loss 0.215888;Validation Loss 0.072095; Train Acc 0.950041; Val Acc 0.974888\n","Final Training Loss: 0.21588833630084991\n","Final Validation Loss: 0.07209505885839462\n","Final Training Accuracy: 0.9500410846343468\n","Final Validation Accuracy: 0.9748878923766816\n","Model 14 Neurons 200 Epochs 5 Learning Rate 0.0001 Pooling Setting 2\n","Epoch 1; Train Loss 0.727568;Validation Loss 0.741627; Train Acc 0.531635; Val Acc 0.156951\n","Epoch 2; Train Loss 0.250273;Validation Loss 0.409348; Train Acc 0.927527; Val Acc 0.956054\n","Epoch 3; Train Loss 0.221604;Validation Loss 0.332694; Train Acc 0.934265; Val Acc 0.919283\n","Epoch 4; Train Loss 0.032212;Validation Loss 0.116864; Train Acc 0.925883; Val Acc 0.973991\n","Epoch 5; Train Loss 0.239278;Validation Loss 0.212595; Train Acc 0.950698; Val Acc 0.965919\n","Final Training Loss: 0.2392776757478714\n","Final Validation Loss: 0.21259485185146332\n","Final Training Accuracy: 0.9506984387838948\n","Final Validation Accuracy: 0.9659192825112107\n","Model 15 Neurons 200 Epochs 5 Learning Rate 1e-05 Pooling Setting 0\n","Epoch 1; Train Loss 0.687043;Validation Loss 0.702237; Train Acc 0.538373; Val Acc 0.262780\n","Epoch 2; Train Loss 0.667943;Validation Loss 0.691377; Train Acc 0.559244; Val Acc 0.232287\n","Epoch 3; Train Loss 0.674420;Validation Loss 0.703970; Train Acc 0.572227; Val Acc 0.221525\n","Epoch 4; Train Loss 0.654259;Validation Loss 0.703759; Train Acc 0.603944; Val Acc 0.281614\n","Epoch 5; Train Loss 0.653135;Validation Loss 0.693816; Train Acc 0.674938; Val Acc 0.539910\n","Final Training Loss: 0.653134822845459\n","Final Validation Loss: 0.6938162446022034\n","Final Training Accuracy: 0.6749383730484799\n","Final Validation Accuracy: 0.5399103139013453\n","Model 16 Neurons 200 Epochs 5 Learning Rate 1e-05 Pooling Setting 1\n","Epoch 1; Train Loss 0.666198;Validation Loss 0.714933; Train Acc 0.530320; Val Acc 0.152466\n","Epoch 2; Train Loss 0.706580;Validation Loss 0.718389; Train Acc 0.529334; Val Acc 0.150673\n","Epoch 3; Train Loss 0.634116;Validation Loss 0.723093; Train Acc 0.529006; Val Acc 0.148879\n","Epoch 4; Train Loss 0.620110;Validation Loss 0.700032; Train Acc 0.529663; Val Acc 0.150673\n","Epoch 5; Train Loss 0.676147;Validation Loss 0.647870; Train Acc 0.530156; Val Acc 0.152466\n","Final Training Loss: 0.6761470437049866\n","Final Validation Loss: 0.6478704214096069\n","Final Training Accuracy: 0.5301561216105176\n","Final Validation Accuracy: 0.15246636771300448\n","Model 17 Neurons 200 Epochs 5 Learning Rate 1e-05 Pooling Setting 2\n","Epoch 1; Train Loss 0.693168;Validation Loss 0.682860; Train Acc 0.638948; Val Acc 0.870852\n","Epoch 2; Train Loss 0.685932;Validation Loss 0.699448; Train Acc 0.554971; Val Acc 0.191031\n","Epoch 3; Train Loss 0.658399;Validation Loss 0.684422; Train Acc 0.527527; Val Acc 0.147982\n","Epoch 4; Train Loss 0.715709;Validation Loss 0.713925; Train Acc 0.525719; Val Acc 0.142601\n","Epoch 5; Train Loss 0.723545;Validation Loss 0.726538; Train Acc 0.525719; Val Acc 0.142601\n","Final Training Loss: 0.7235446572303772\n","Final Validation Loss: 0.7265375852584839\n","Final Training Accuracy: 0.5257189811010682\n","Final Validation Accuracy: 0.14260089686098654\n","Model 18 Neurons 200 Epochs 10 Learning Rate 0.0001 Pooling Setting 0\n","Epoch 1; Train Loss 0.698219;Validation Loss 0.365052; Train Acc 0.616270; Val Acc 0.882511\n","Epoch 2; Train Loss 0.207642;Validation Loss 0.326751; Train Acc 0.878554; Val Acc 0.937220\n","Epoch 3; Train Loss 0.364409;Validation Loss 0.472281; Train Acc 0.867214; Val Acc 0.892377\n","Epoch 4; Train Loss 0.083508;Validation Loss 0.178827; Train Acc 0.917338; Val Acc 0.941704\n","Epoch 5; Train Loss 0.096971;Validation Loss 0.160746; Train Acc 0.903862; Val Acc 0.953363\n","Epoch 6; Train Loss 0.466546;Validation Loss 0.141628; Train Acc 0.927691; Val Acc 0.954260\n","Epoch 7; Train Loss 0.168853;Validation Loss 0.199693; Train Acc 0.940016; Val Acc 0.949776\n","Epoch 8; Train Loss 0.098261;Validation Loss 0.133647; Train Acc 0.934922; Val Acc 0.943498\n","Epoch 9; Train Loss 0.157136;Validation Loss 0.197728; Train Acc 0.947247; Val Acc 0.953363\n","Epoch 10; Train Loss 0.057128;Validation Loss 0.129252; Train Acc 0.949219; Val Acc 0.947982\n","Final Training Loss: 0.05712784454226494\n","Final Validation Loss: 0.12925167381763458\n","Final Training Accuracy: 0.9492193919474117\n","Final Validation Accuracy: 0.9479820627802691\n","Model 19 Neurons 200 Epochs 10 Learning Rate 0.0001 Pooling Setting 1\n","Epoch 1; Train Loss 0.535849;Validation Loss 0.706519; Train Acc 0.548562; Val Acc 0.196413\n","Epoch 2; Train Loss 0.393353;Validation Loss 0.353997; Train Acc 0.942975; Val Acc 0.954260\n","Epoch 3; Train Loss 0.145709;Validation Loss 0.378507; Train Acc 0.954314; Val Acc 0.959641\n","Epoch 4; Train Loss 0.209487;Validation Loss 0.271393; Train Acc 0.952342; Val Acc 0.965022\n","Epoch 5; Train Loss 0.294722;Validation Loss 0.371641; Train Acc 0.949548; Val Acc 0.950673\n","Epoch 6; Train Loss 0.111478;Validation Loss 0.110153; Train Acc 0.961052; Val Acc 0.972197\n","Epoch 7; Train Loss 0.377065;Validation Loss 0.062286; Train Acc 0.959573; Val Acc 0.973991\n","Epoch 8; Train Loss 0.068131;Validation Loss 0.081086; Train Acc 0.957272; Val Acc 0.971300\n","Epoch 9; Train Loss 0.288483;Validation Loss 0.141083; Train Acc 0.956779; Val Acc 0.973094\n","Epoch 10; Train Loss 0.038651;Validation Loss 0.062013; Train Acc 0.952013; Val Acc 0.974888\n","Final Training Loss: 0.03865055739879608\n","Final Validation Loss: 0.06201300024986267\n","Final Training Accuracy: 0.952013147082991\n","Final Validation Accuracy: 0.9748878923766816\n","Model 20 Neurons 200 Epochs 10 Learning Rate 0.0001 Pooling Setting 2\n","Epoch 1; Train Loss 0.301388;Validation Loss 0.990503; Train Acc 0.533936; Val Acc 0.158744\n","Epoch 2; Train Loss 0.446567;Validation Loss 0.668234; Train Acc 0.856204; Val Acc 0.794619\n","Epoch 3; Train Loss 0.354735;Validation Loss 0.397058; Train Acc 0.947740; Val Acc 0.953363\n","Epoch 4; Train Loss 0.308959;Validation Loss 0.287450; Train Acc 0.951520; Val Acc 0.957848\n","Epoch 5; Train Loss 0.170419;Validation Loss 0.217546; Train Acc 0.954150; Val Acc 0.967713\n","Epoch 6; Train Loss 0.038017;Validation Loss 0.222807; Train Acc 0.949384; Val Acc 0.973094\n","Epoch 7; Train Loss 0.087947;Validation Loss 0.087671; Train Acc 0.953164; Val Acc 0.973991\n","Epoch 8; Train Loss 0.091189;Validation Loss 0.161899; Train Acc 0.956779; Val Acc 0.972197\n","Epoch 9; Train Loss 0.080572;Validation Loss 0.128596; Train Acc 0.954971; Val Acc 0.973094\n","Epoch 10; Train Loss 0.218725;Validation Loss 0.068644; Train Acc 0.956943; Val Acc 0.972197\n","Final Training Loss: 0.2187245488166809\n","Final Validation Loss: 0.06864425539970398\n","Final Training Accuracy: 0.9569433032046015\n","Final Validation Accuracy: 0.9721973094170404\n","Model 21 Neurons 200 Epochs 10 Learning Rate 1e-05 Pooling Setting 0\n","Epoch 1; Train Loss 0.708439;Validation Loss 0.683354; Train Acc 0.622843; Val Acc 0.824215\n","Epoch 2; Train Loss 0.690797;Validation Loss 0.677306; Train Acc 0.672802; Val Acc 0.794619\n","Epoch 3; Train Loss 0.690383;Validation Loss 0.680116; Train Acc 0.702547; Val Acc 0.746188\n","Epoch 4; Train Loss 0.677441;Validation Loss 0.691145; Train Acc 0.717666; Val Acc 0.712108\n","Epoch 5; Train Loss 0.675130;Validation Loss 0.675961; Train Acc 0.743961; Val Acc 0.714798\n","Epoch 6; Train Loss 0.450700;Validation Loss 0.460795; Train Acc 0.901561; Val Acc 0.914798\n","Epoch 7; Train Loss 0.486572;Validation Loss 0.332248; Train Acc 0.881841; Val Acc 0.909417\n","Epoch 8; Train Loss 0.444777;Validation Loss 0.468388; Train Acc 0.906163; Val Acc 0.934529\n","Epoch 9; Train Loss 0.278729;Validation Loss 0.407385; Train Acc 0.915037; Val Acc 0.920179\n","Epoch 10; Train Loss 0.226614;Validation Loss 0.222404; Train Acc 0.912243; Val Acc 0.942601\n","Final Training Loss: 0.2266143262386322\n","Final Validation Loss: 0.22240419685840607\n","Final Training Accuracy: 0.9122432210353328\n","Final Validation Accuracy: 0.9426008968609866\n","Model 22 Neurons 200 Epochs 10 Learning Rate 1e-05 Pooling Setting 1\n","Epoch 1; Train Loss 0.682083;Validation Loss 0.692184; Train Acc 0.700082; Val Acc 0.496861\n","Epoch 2; Train Loss 0.693693;Validation Loss 0.702598; Train Acc 0.562038; Val Acc 0.205381\n","Epoch 3; Train Loss 0.700102;Validation Loss 0.707592; Train Acc 0.547247; Val Acc 0.178475\n","Epoch 4; Train Loss 0.645948;Validation Loss 0.660137; Train Acc 0.542317; Val Acc 0.171300\n","Epoch 5; Train Loss 0.663225;Validation Loss 0.713078; Train Acc 0.543632; Val Acc 0.172197\n","Epoch 6; Train Loss 0.598691;Validation Loss 0.712408; Train Acc 0.548891; Val Acc 0.186547\n","Epoch 7; Train Loss 0.680561;Validation Loss 0.679318; Train Acc 0.575349; Val Acc 0.225112\n","Epoch 8; Train Loss 0.590813;Validation Loss 0.682102; Train Acc 0.627938; Val Acc 0.328251\n","Epoch 9; Train Loss 0.693366;Validation Loss 0.697928; Train Acc 0.712736; Val Acc 0.497758\n","Epoch 10; Train Loss 0.634266;Validation Loss 0.658515; Train Acc 0.902876; Val Acc 0.860987\n","Final Training Loss: 0.6342659592628479\n","Final Validation Loss: 0.6585150957107544\n","Final Training Accuracy: 0.9028759244042728\n","Final Validation Accuracy: 0.8609865470852018\n","Model 23 Neurons 200 Epochs 10 Learning Rate 1e-05 Pooling Setting 2\n","Epoch 1; Train Loss 0.687182;Validation Loss 0.686133; Train Acc 0.471323; Val Acc 0.826906\n","Epoch 2; Train Loss 0.697303;Validation Loss 0.686642; Train Acc 0.658340; Val Acc 0.414350\n","Epoch 3; Train Loss 0.690779;Validation Loss 0.705430; Train Acc 0.533279; Val Acc 0.165919\n","Epoch 4; Train Loss 0.705874;Validation Loss 0.711620; Train Acc 0.527198; Val Acc 0.150673\n","Epoch 5; Train Loss 0.715596;Validation Loss 0.724385; Train Acc 0.526541; Val Acc 0.148879\n","Epoch 6; Train Loss 0.702520;Validation Loss 0.724315; Train Acc 0.528020; Val Acc 0.149776\n","Epoch 7; Train Loss 0.610153;Validation Loss 0.719373; Train Acc 0.529499; Val Acc 0.154260\n","Epoch 8; Train Loss 0.654030;Validation Loss 0.714220; Train Acc 0.538866; Val Acc 0.175785\n","Epoch 9; Train Loss 0.452201;Validation Loss 0.557983; Train Acc 0.800493; Val Acc 0.905830\n","Epoch 10; Train Loss 0.234615;Validation Loss 0.592369; Train Acc 0.888414; Val Acc 0.852915\n","Final Training Loss: 0.23461493849754333\n","Final Validation Loss: 0.5923691987991333\n","Final Training Accuracy: 0.8884141331142152\n","Final Validation Accuracy: 0.852914798206278\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsK-WF0Dlivu","executionInfo":{"status":"ok","timestamp":1615739970081,"user_tz":360,"elapsed":94087,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"815ec6bb-174c-4328-cad0-158602cbc41e"},"source":["#Model 19 (counting from 0 to 23) Neurons 200 Epochs 10 Learning Rate 0.0001 Pooling Setting 1\r\n","bestRNN = CatRNN(input_size = vocab_len, hidden_size = 200, pooling = 1) #Max pooling\r\n","train_myRNN(bestRNN ,train_iter,valid_iter,num_epochs= 10,learning_rate=0.0001, plot_q = False)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Epoch 1; Train Loss 0.693887;Validation Loss 0.695739; Train Acc 0.709449; Val Acc 0.484305\n","Epoch 2; Train Loss 0.427741;Validation Loss 0.303742; Train Acc 0.941660; Val Acc 0.947982\n","Epoch 3; Train Loss 0.092595;Validation Loss 0.164530; Train Acc 0.926376; Val Acc 0.976682\n","Epoch 4; Train Loss 0.526404;Validation Loss 0.302320; Train Acc 0.943796; Val Acc 0.943498\n","Epoch 5; Train Loss 0.140813;Validation Loss 0.224647; Train Acc 0.956450; Val Acc 0.963229\n","Epoch 6; Train Loss 0.055365;Validation Loss 0.274999; Train Acc 0.949712; Val Acc 0.973094\n","Epoch 7; Train Loss 0.206673;Validation Loss 0.223310; Train Acc 0.962038; Val Acc 0.969507\n","Epoch 8; Train Loss 0.018968;Validation Loss 0.083099; Train Acc 0.959080; Val Acc 0.973094\n","Epoch 9; Train Loss 0.172697;Validation Loss 0.316467; Train Acc 0.963681; Val Acc 0.968610\n","Epoch 10; Train Loss 0.075936;Validation Loss 0.043830; Train Acc 0.951684; Val Acc 0.973991\n","Final Training Loss: 0.07593569904565811\n","Final Validation Loss: 0.04382999613881111\n","Final Training Accuracy: 0.9516844700082169\n","Final Validation Accuracy: 0.9739910313901345\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fE3eRkDAa91F"},"source":["### Part (c) [4 pt]\n","\n","Choose at least 4 hyperparameters to tune. Explain how you tuned the hyperparameters.\n","You don't need to include your training curve for every model you trained.\n","Instead, explain what hyperparemters you tuned, what the best validation accuracy was,\n","and the reasoning behind the hyperparameter decisions you made.\n","\n","For this assignment, you should tune more than just your learning rate and epoch. \n","Choose at least 2 hyperparameters that are unrelated to the optimizer."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"A2GEWfDca91G","executionInfo":{"status":"ok","timestamp":1615736085613,"user_tz":360,"elapsed":49374,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#Hyperparameters: Pooling Method, Hidden Layer Size, Learning Rate, Epochs\r\n","\r\n","#Choose at least 4 hyperparameters to tune. Explain how you tuned the hyperparameters.\r\n","\r\n","#To tune the hyperparameters I a for loop and sets of values for the hyperparameters to try out all possible combinations (24):\r\n","\r\n","  #Learning Rate: I chose between 1e-4 and 1e-5 to try out my standard learning rate (which is bigger than some usual standard learning rates like 1e-5) vesus a more \r\n","    #standard (and smaller) learning rate.\r\n","  #Pooling: I decided to go over all possible pooling forms to  try out which one gives the best performance in regards to each other when solving this \r\n","    #problem.\r\n","  #Number of Epochs: Since during my testing the epoch number required has so far been low I am only increasing it between 5 and 10 for all models, due to the so far\r\n","    #quick convergence.\r\n","  #Hidden layer size/Neuron number: I decided to tune between the standard vocab size and an almost double number (200) to see the computational impact of such endeavours.\r\n","\r\n","#Best validation accuracy: 0.9748878923766816 for model 19 (0.9739910313901345 when reproduced)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v7DY56rKa91I"},"source":["### Part (d) [2 pt]\n","\n","Before we deploy a machine learning model, we usually want to have a better understanding\n","of how our model performs beyond its validation accuracy. An important metric to track is\n","*how well our model performs in certain subsets of the data*.\n","\n","In particular, what is the model's error rate amongst data with negative labels?\n","This is called the **false positive rate**.\n","\n","What about the model's error rate amongst data with positive labels?\n","This is called the **false negative rate**.\n","\n","Report your final model's false positive and false negative rate across the\n","validation set."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"7ggbQSdba91J","executionInfo":{"status":"ok","timestamp":1615740591151,"user_tz":360,"elapsed":265,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["# Create a Dataset of only spam validation examples\n","valid_spam = torchtext.data.Dataset(\n","    [e for e in valid.examples if e.label == 1],\n","    valid.fields)\n","# Create a Dataset of only non-spam validation examples\n","valid_nospam = torchtext.data.Dataset(\n","    [e for e in valid.examples if e.label == 0],\n","    valid.fields)\n","\n","valid_nospam_iter = torchtext.data.BucketIterator(valid_nospam,\n","                                           batch_size=32,\n","                                           sort_key=lambda x: len(x.sms), # to minimize padding\n","                                           sort_within_batch=True,        # sort within each batch\n","                                           repeat=False)                  # repeat the iterator for many epochs\n","valid_spam_iter = torchtext.data.BucketIterator(valid_spam,\n","                                           batch_size=32,\n","                                           sort_key=lambda x: len(x.sms), # to minimize padding\n","                                           sort_within_batch=True,        # sort within each batch\n","                                           repeat=False)                  # repeat the iterator for many epochs"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqq4XcmmodPG","executionInfo":{"status":"ok","timestamp":1615740592923,"user_tz":360,"elapsed":581,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"81854e04-79cc-41d1-ae48-e7022f8b65d4"},"source":["print(\"False negative rate {}.\".format(1 - get_accuracy(bestRNN, valid_spam_iter)))\r\n","print(\"False positive rate {}.\".format(1 - get_accuracy(bestRNN, valid_nospam_iter)))\r\n"],"execution_count":34,"outputs":[{"output_type":"stream","text":["False negative rate 0.08805031446540879.\n","False positive rate 0.014644351464435101.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N1iRteb3a91O"},"source":["### Part (e) [2 pt]\n","\n","The impact of a false positive vs a false negative can be drastically different.\n","If our spam detection algorithm was deployed on your phone, what is the impact\n","of a false positive on the phone's user? What is the impact of a false negative?"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"hFLUOJTGa91Q","executionInfo":{"status":"ok","timestamp":1615736085615,"user_tz":360,"elapsed":49369,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#Impact of False Positive: If a sms that isnt spam gets put into spam the user could lose potentially important information for them.\r\n","#Impact of False Negative: If a sms that is spam doesnt get put into spam the user's experience would be compromised because they could find it hard to discern them amongst\r\n","#important messages at first glance, therefore making it annoying to browse through their mailbox and delete the spam message themselves."],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gznefulsa91V"},"source":["## Part 4. Evaluation [11 pt]\n","\n","### Part (a) [1 pt]\n","\n","Report the final test accuracy of your model."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"D5L5D-A1a91W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615740884783,"user_tz":360,"elapsed":710,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"14994b9d-14b3-43a5-e384-14d1e546f97f"},"source":["print(\"Final Test Accuracy {}.\".format(get_accuracy(bestRNN, test_iter)))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Final Test Accuracy 0.9748653500897666.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6Hjmd8rca91Y"},"source":["### Part (b) [3 pt]\n","\n","Report the false positive rate and false negative rate of your model across the test set."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"GFiAKztJa91Z","executionInfo":{"status":"ok","timestamp":1615741046435,"user_tz":360,"elapsed":277,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#Copied from above (when we did the validation case) and barely modified\r\n","# Create a Dataset of only spam test examples\r\n","test_spam = torchtext.data.Dataset(\r\n","    [e for e in test.examples if e.label == 1],\r\n","    test.fields)\r\n","# Create a Dataset of only non-spam test examples\r\n","test_nospam = torchtext.data.Dataset(\r\n","    [e for e in test.examples if e.label == 0],\r\n","    test.fields)\r\n","\r\n","test_nospam_iter = torchtext.data.BucketIterator(test_nospam,\r\n","                                           batch_size=32,\r\n","                                           sort_key=lambda x: len(x.sms), # to minimize padding\r\n","                                           sort_within_batch=True,        # sort within each batch\r\n","                                           repeat=False)                  # repeat the iterator for many epochs\r\n","test_spam_iter = torchtext.data.BucketIterator(test_spam,\r\n","                                           batch_size=32,\r\n","                                           sort_key=lambda x: len(x.sms), # to minimize padding\r\n","                                           sort_within_batch=True,        # sort within each batch\r\n","                                           repeat=False)                  # repeat the iterator for many epochs"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChgWxDXoq0dr","executionInfo":{"status":"ok","timestamp":1615741048281,"user_tz":360,"elapsed":731,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"032f7267-3fa6-454b-a335-17cde58250b9"},"source":["print(\"False negative rate {}.\".format(1 - get_accuracy(bestRNN, test_spam_iter)))\r\n","print(\"False positive rate {}.\".format(1 - get_accuracy(bestRNN, test_nospam_iter)))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["False negative rate 0.1145038167938931.\n","False positive rate 0.01322482197355035.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0jGHtQFpa91b"},"source":["### Part (c) [3 pt]\n","\n","What is your model's prediction of the **probability** that\n","the SMS message \"machine learning is sooo cool!\" is spam?\n","\n","Hint: To begin, use `text_field.vocab.stoi` to look up the index\n","of each character in the vocabulary."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"h_2nSJq8a91b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615741426536,"user_tz":360,"elapsed":263,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"ef19ff44-051a-452f-dfe7-b0304046cc46"},"source":["msg = \"machine learning is sooo cool!\"\r\n","msg_tk = []\r\n","for char in msg:\r\n","  msg_tk.append(torch.tensor(text_field.vocab.stoi[char]))\r\n","msg_tk_f = torch.stack(msg_tk)\r\n","msg_tk_f.unsqueeze_(0)\r\n","print(\"Probability msg is spam: \")\r\n","print(F.softmax(bestRNN(msg_tk_f), dim=1)[0][1].item())"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Probability msg is spam: \n","0.04967055097222328\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QD1zgYJpa91f"},"source":["### Part (d) [4 pt]\n","\n","Do you think detecting spam is an easy or difficult task?\n","\n","Since machine learning models are expensive to train and deploy, it is very\n","important to compare our models against baseline models: a simple\n","model that is easy to build and inexpensive to run that we can compare our\n","recurrent neural network model against.\n","\n","Explain how you might build a simple baseline model. This baseline model\n","can be a simple neural network (with very few weights), a hand-written algorithm,\n","or any other strategy that is easy to build and test.\n","\n","**Do not actually build a baseline model. Instead, provide instructions on\n","how to build it.**"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"LTndp-IOa91g","executionInfo":{"status":"ok","timestamp":1615741986608,"user_tz":360,"elapsed":268,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}}},"source":["#We could use a simple algorithm with two databases to build a baseline model;\r\n","#this model would essentially do the following:\r\n","#1.-Load in a database of suspicious words, and have a database (empty so far)\r\n","#of suspicious email addresses/phone numbers\r\n","#2.-First, it would search its suspicious address/phone number database to\r\n","#automatically label a message base on its source (on first iteration this \r\n","#wouldnt be of any use since it builds up its database as it encounters spam).\r\n","#Then it would take in messages as strings of words and compare them against\r\n","#its database of suspicous words\r\n","#3.-If it finds a suspicious word (or more than a certain threshold) add\r\n","#the email address/phone number to its suspicious email/phone number database,\r\n","#this way it automatically labels as spam anything coming from said sources.\r\n","#4.-Repeat from 2 onwards for each message"],"execution_count":43,"outputs":[]}]}